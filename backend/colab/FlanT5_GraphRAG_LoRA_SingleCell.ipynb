{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install deps\n",
        "!pip -q install \"transformers>=4.44.0\" datasets peft accelerate sentencepiece \\\n                 \"chromadb>=0.5.0\" \"sentence-transformers>=3.0.1\"\n\n",
        "import os, json, random, zipfile\n",
        "from typing import Dict, List\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from chromadb.utils import embedding_functions\n\n",
        "# Config\n",
        "BASE_MODEL = \"google/flan-t5-small\"\n",
        "ADAPTER_DIR = \"/content/flan_t5_dosha_lora\"\n",
        "CHROMA_DIR  = \"/content/chroma_db\"\n",
        "SEED = 42\n",
        "MAX_SOURCE_LEN = 512\n",
        "MAX_TARGET_LEN = 256\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device, torch.cuda.get_device_name(0) if device==\"cuda\" else \"\")\n\n",
        "# GPU dtype (bf16 if supported, else fp16 on CUDA, else float32)\n",
        "def pick_dtype():\n",
        "    if device == \"cuda\":\n",
        "        try:\n",
        "            if torch.cuda.is_bf16_supported():\n",
        "                return torch.bfloat16\n",
        "            return torch.float16\n",
        "        except Exception:\n",
        "            return torch.float16\n",
        "    return torch.float32\n",
        "DTYPE = pick_dtype()\n",
        "print(\"torch_dtype:\", DTYPE)\n\n",
        "# Ayurvedic KB (for GraphRAG)\n",
        "AYURVEDA_KNOWLEDGE: List[Dict] = [\n",
        "    {\"id\":\"dosha_vata\",\"category\":\"Doshas\",\"title\":\"Vata\",\"content\":\"Vata governs movement; imbalance → anxiety, dry skin, constipation.\",\"metadata\":{\"type\":\"constitution\",\"dosha\":\"vata\"}},\n",
        "    {\"id\":\"dosha_pitta\",\"category\":\"Doshas\",\"title\":\"Pitta\",\"content\":\"Pitta governs digestion; imbalance → inflammation, anger, heartburn, skin issues.\",\"metadata\":{\"type\":\"constitution\",\"dosha\":\"pitta\"}},\n",
        "    {\"id\":\"dosha_kapha\",\"category\":\"Doshas\",\"title\":\"Kapha\",\"content\":\"Kapha governs structure; imbalance → lethargy, congestion, weight gain.\",\"metadata\":{\"type\":\"constitution\",\"dosha\":\"kapha\"}},\n",
        "    {\"id\":\"herb_ashwagandha\",\"category\":\"Herbs\",\"title\":\"Ashwagandha\",\"content\":\"Adaptogen: stress reduction, sleep, cognition. Balances Vata/Kapha.\",\"metadata\":{\"type\":\"herb\"}},\n",
        "    {\"id\":\"herb_turmeric\",\"category\":\"Herbs\",\"title\":\"Turmeric\",\"content\":\"Anti-inflammatory/antioxidant; supports skin, joints, liver.\",\"metadata\":{\"type\":\"herb\"}},\n",
        "    {\"id\":\"diet_vata\",\"category\":\"Diet\",\"title\":\"Vata Diet\",\"content\":\"Warm, moist, grounding foods; ghee; avoid cold/dry foods.\",\"metadata\":{\"type\":\"diet\",\"dosha\":\"vata\"}},\n",
        "    {\"id\":\"diet_pitta\",\"category\":\"Diet\",\"title\":\"Pitta Diet\",\"content\":\"Cooling, hydrating foods; avoid hot/fried/acidic foods.\",\"metadata\":{\"type\":\"diet\",\"dosha\":\"pitta\"}},\n",
        "    {\"id\":\"diet_kapha\",\"category\":\"Diet\",\"title\":\"Kapha Diet\",\"content\":\"Light, warm, pungent foods; reduce heavy/oily/sweet.\",\"metadata\":{\"type\":\"diet\",\"dosha\":\"kapha\"}},\n",
        "    {\"id\":\"practice_abhyanga\",\"category\":\"Practices\",\"title\":\"Abhyanga\",\"content\":\"Daily oil massage: sesame(Vata), coconut(Pitta), mustard/sunflower(Kapha).\",\"metadata\":{\"type\":\"practice\"}}\n",
        "]\n\n",
        "# Init ChromaDB\n",
        "def init_chromadb(persist=CHROMA_DIR):\n",
        "    os.makedirs(persist, exist_ok=True)\n",
        "    client = chromadb.Client(Settings(persist_directory=persist, anonymized_telemetry=False))\n",
        "    try:\n",
        "        coll = client.get_collection(\"ayurveda_knowledge\")\n",
        "    except Exception:\n",
        "        ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
        "        coll = client.create_collection(name=\"ayurveda_knowledge\", embedding_function=ef,\n",
        "                                        metadata={\"description\":\"Ayurveda KB for RAG\"})\n",
        "        coll.add(documents=[d[\"content\"] for d in AYURVEDA_KNOWLEDGE],\n",
        "                 metadatas=[d[\"metadata\"] for d in AYURVEDA_KNOWLEDGE],\n",
        "                 ids=[d[\"id\"] for d in AYURVEDA_KNOWLEDGE])\n",
        "    return client, coll\n\n",
        "client, collection = init_chromadb()\n",
        "print(\"Chroma docs:\", collection.count())\n\n",
        "# Data: upload JSONL (input/output) or use demo\n",
        "DEMO = [\n",
        "  {\"input\":\"Dosha: Vata-Pitta\\nSymptoms: bloating, anxiety\\nContext: adult, moderate\",\n",
        "   \"output\":\"Health:\\n- Regular routine; manage stress.\\nDiet:\\n- Cooling + warm cooked foods, ghee.\\nLifestyle:\\n- Abhyanga (sesame), breathwork.\\nWarnings:\\n- If pain or bleeding, consult doctor.\"},\n",
        "  {\"input\":\"Dosha: Kapha\\nSymptoms: fatigue, congestion\\nContext: adult, mild\",\n",
        "   \"output\":\"Health:\\n- Daily vigorous exercise.\\nDiet:\\n- Light, warm, pungent foods.\\nLifestyle:\\n- Wake before 6 AM; avoid naps.\\nWarnings:\\n- If breathlessness/edema, seek care.\"},\n",
        "  {\"input\":\"Dosha: Pitta\\nSymptoms: rash, burning\\nContext: adult, mild\",\n",
        "   \"output\":\"Health:\\n- Reduce heat; aloe/coconut oil topicals.\\nDiet:\\n- Cooling foods; avoid spicy/acidic.\\nLifestyle:\\n- Avoid midday sun.\\nWarnings:\\n- If rash spreads, consult clinician.\"}\n",
        "]\n\n",
        "on_colab = False\n",
        "try:\n",
        "    import google.colab as _gc  # type: ignore\n",
        "    on_colab = True\n",
        "except Exception:\n",
        "    pass\n\n",
        "if on_colab:\n",
        "    from google.colab import files\n",
        "    print(\"OPTIONAL: Upload your JSONL (fields: input, output). If you skip, demo data will be used.\")\n",
        "    up = files.upload()\n",
        "    if up:\n",
        "        fname = list(up.keys())[0]\n",
        "        rows=[]\n",
        "        with open(fname,\"r\",encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                o=json.loads(line)\n",
        "                rows.append({\"input\":o[\"input\"],\"target\":o[\"output\"]})\n",
        "        ds = Dataset.from_list(rows)\n",
        "    else:\n",
        "        ds = Dataset.from_list(DEMO).map(lambda ex: {\"target\": ex[\"output\"]})\n",
        "else:\n",
        "    ds = Dataset.from_list(DEMO).map(lambda ex: {\"target\": ex[\"output\"]})\n\n",
        "def to_prompt(ex):\n",
        "    return {\n",
        "      \"input_text\": \"You are an Ayurvedic assistant. Generate concise, specific, non-repetitive recommendations.\\n\"\n",
        "                    \"Return sections: Health, Diet, Lifestyle, Warnings.\\n\\n\"\n",
        "                    + ex[\"input\"] + \"\\n\\nAnswer:\",\n",
        "      \"labels\": ex[\"target\"],\n",
        "    }\n\n",
        "ds = ds.map(to_prompt)\n",
        "split = ds.train_test_split(test_size=0.1, seed=SEED)\n",
        "train_ds, val_ds = split[\"train\"], split[\"test\"]\n\n",
        "# Load model/tokenizer with GPU dtype\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "base = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL, torch_dtype=DTYPE)\n",
        "if device == \"cuda\":\n",
        "    base = base.to(device)\n\n",
        "# LoRA\n",
        "lora_cfg = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q\",\"k\",\"v\",\"o\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_2_SEQ_LM\")\n",
        "model = get_peft_model(base, lora_cfg)\n",
        "if device == \"cuda\":\n",
        "    model = model.to(device)\n\n",
        "# Tokenization\n",
        "def tok(batch):\n",
        "    mi = tokenizer(batch[\"input_text\"], max_length=MAX_SOURCE_LEN, truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        lab = tokenizer(batch[\"labels\"], max_length=MAX_TARGET_LEN, truncation=True)\n",
        "    mi[\"labels\"] = lab[\"input_ids\"]\n",
        "    return mi\n\n",
        "collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "train_tok = train_ds.map(tok, batched=True, remove_columns=train_ds.column_names)\n",
        "val_tok   = val_ds.map(tok,   batched=True, remove_columns=val_ds.column_names)\n\n",
        "# Train\n",
        "args = TrainingArguments(\n",
        "    output_dir=ADAPTER_DIR,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    eval_steps=200,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.03,\n",
        "    weight_decay=0.01,\n",
        "    bf16=(DTYPE==torch.bfloat16),\n",
        "    fp16=(DTYPE==torch.float16),\n",
        "    report_to=\"none\",\n",
        ")\n\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_tok, eval_dataset=val_tok,\n",
        "                  tokenizer=tokenizer, data_collator=collator)\n",
        "print(\"Training LoRA...\")\n",
        "trainer.train()\n",
        "os.makedirs(ADAPTER_DIR, exist_ok=True)\n",
        "model.save_pretrained(ADAPTER_DIR)\n",
        "tokenizer.save_pretrained(ADAPTER_DIR)\n",
        "print(\"Saved adapter at:\", ADAPTER_DIR)\n\n",
        "# GraphRAG inference (retrieve + generate)\n",
        "def retrieve(query: str, n=5) -> List[str]:\n",
        "    res = collection.query(query_texts=[query], n_results=n)\n",
        "    return (res.get(\"documents\",[[]])[0]) or []\n\n",
        "@torch.no_grad()\n",
        "def generate_with_rag(user_input: str, max_len: int = 280) -> str:\n",
        "    ctx_docs = retrieve(user_input, n=5)\n",
        "    context = \"\\n\\n\".join([f\"Source {i+1}: {d}\" for i,d in enumerate(ctx_docs)])\n",
        "    prompt = (\"Based on the following Ayurvedic knowledge, generate concise, specific recommendations.\\n\"\n",
        "              \"Return sections: Health, Diet, Lifestyle, Warnings.\\n\\n\"\n",
        "              f\"Context:\\n{context}\\n\\nInput:\\n{user_input}\\n\\nAnswer:\")\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=MAX_SOURCE_LEN, truncation=True)\n",
        "    if device==\"cuda\": inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "    out = model.generate(**inputs, max_length=max_len, min_length=80,\n",
        "                         num_beams=5, early_stopping=True,\n",
        "                         temperature=0.9, do_sample=True, top_k=60, top_p=0.92,\n",
        "                         repetition_penalty=1.25, no_repeat_ngram_size=3)\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)\n\n",
        "print(\"\\nDemo RAG output:\")\n",
        "print(generate_with_rag(\"Dosha: Vata-Pitta\\nSymptoms: bloating, anxiety\\nContext: adult, moderate severity\"))\n\n",
        "# Zip adapter for download\n",
        "zip_path = \"/content/flan_t5_dosha_lora.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, _, files in os.walk(ADAPTER_DIR):\n",
        "        for f in files:\n",
        "            full = os.path.join(root, f)\n",
        "            rel  = os.path.relpath(full, ADAPTER_DIR)\n",
        "            zf.write(full, arcname=os.path.join(\"flan_t5_dosha_lora\", rel))\n",
        "print(\"Download from left pane:\", zip_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "version": "3"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
